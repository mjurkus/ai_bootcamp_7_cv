{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEN Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the project is to build a model able to generate [Forsythâ€“Edwards Notation\n",
    "](https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation) (FEN) description based on a schematic image of a chess board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from toai.imports import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring GPU to allow memory growth to avoid OOM kernel crashes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Device placement logging must be set at program startup",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-92982b93c013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_log_device_placement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Currently, memory growth needs to be the same across GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mset_log_device_placement\u001b[0;34m(enabled)\u001b[0m\n\u001b[1;32m   1588\u001b[0m     \u001b[0menabled\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0menabled\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0mplacement\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1589\u001b[0m   \"\"\"\n\u001b[0;32m-> 1590\u001b[0;31m   \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_device_placement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mlog_device_placement\u001b[0;34m(self, enabled)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       raise RuntimeError(\n\u001b[0;32m-> 1289\u001b[0;31m           \"Device placement logging must be set at program startup\")\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_device_placement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Device placement logging must be set at program startup"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(False)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            print(gpu)\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define datasets for data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('data/chess')\n",
    "TEMP_DIR = Path('temp/chess')\n",
    "TRAIN_DATA_DIR = DATA_DIR/\"train\"\n",
    "TEST_DATA_DIR = DATA_DIR/\"test\"\n",
    "DOWNLOAD_DATA = False\n",
    "TEST_DATA_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_DATA:\n",
    "    !kaggle datasets download -d koryakinp/chess-positions --unzip -p {DATA_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define couple helper classes for easier data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceate_df(data_path):\n",
    "    file_paths = [data_path/fn for fn in os.listdir(data_path)]\n",
    "    tuples = [(path.stem, str(path)) for path in file_paths[:TEST_DATA_SIZE]]\n",
    "    return pd.DataFrame(list(tuples), columns=[\"fen\", \"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ceate_df(TRAIN_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fen</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8-3pPKp1-7p-8-1N4k1-7P-8-7R</td>\n",
       "      <td>data/chess/train/8-3pPKp1-7p-8-1N4k1-7P-8-7R.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KR3k2-8-1P4Pp-3P4-7P-2Nb4-2b4n-4B2N</td>\n",
       "      <td>data/chess/train/KR3k2-8-1P4Pp-3P4-7P-2Nb4-2b4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7n-N5B1-2p5-2KN4-n3r3-N2BrkpB-4r3-8</td>\n",
       "      <td>data/chess/train/7n-N5B1-2p5-2KN4-n3r3-N2BrkpB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1r6-8-1R6-6k1-B7-8-2K5-8</td>\n",
       "      <td>data/chess/train/1r6-8-1R6-6k1-B7-8-2K5-8.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nN4B1-1b1B4-r7-8-5PN1-KPk5-3P4-B1B3R1</td>\n",
       "      <td>data/chess/train/nN4B1-1b1B4-r7-8-5PN1-KPk5-3P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     fen  \\\n",
       "0            8-3pPKp1-7p-8-1N4k1-7P-8-7R   \n",
       "1    KR3k2-8-1P4Pp-3P4-7P-2Nb4-2b4n-4B2N   \n",
       "2    7n-N5B1-2p5-2KN4-n3r3-N2BrkpB-4r3-8   \n",
       "3               1r6-8-1R6-6k1-B7-8-2K5-8   \n",
       "4  nN4B1-1b1B4-r7-8-5PN1-KPk5-3P4-B1B3R1   \n",
       "\n",
       "                                                path  \n",
       "0  data/chess/train/8-3pPKp1-7p-8-1N4k1-7P-8-7R.jpeg  \n",
       "1  data/chess/train/KR3k2-8-1P4Pp-3P4-7P-2Nb4-2b4...  \n",
       "2  data/chess/train/7n-N5B1-2p5-2KN4-n3r3-N2BrkpB...  \n",
       "3     data/chess/train/1r6-8-1R6-6k1-B7-8-2K5-8.jpeg  \n",
       "4  data/chess/train/nN4B1-1b1B4-r7-8-5PN1-KPk5-3P...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_pieses = 'prbnkqPRBNKQ'\n",
    "SQUARE_SIZE = 40\n",
    "IMG_DIM = SQUARE_SIZE * 8\n",
    "IMG_DIMS = (IMG_DIM, IMG_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_from_fen(fen):\n",
    "    eye = np.eye(13)\n",
    "    output = np.empty((0, 13))\n",
    "    fen = re.sub('[-]', '', fen)\n",
    "   \n",
    "    for char in fen:\n",
    "        if(char in '1234|5678'):\n",
    "            output = np.append(output, np.tile(eye[12], (int(char), 1)), axis=0)\n",
    "        else:\n",
    "            idx = chess_pieses.index(char)\n",
    "            output = np.append(output, eye[idx].reshape((1, 13)), axis=0)\n",
    "\n",
    "    return output.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    image = tf.image.resize(image, IMG_DIMS)\n",
    "    \n",
    "    image = tf.expand_dims(image, 0)\n",
    "    patches = tf.image.extract_patches(\n",
    "        images=image, \n",
    "        sizes=[1, SQUARE_SIZE, SQUARE_SIZE, 1], \n",
    "        strides=[1, SQUARE_SIZE, SQUARE_SIZE, 1], \n",
    "        rates=[1, 1, 1, 1],\n",
    "        padding='VALID'\n",
    "    )\n",
    "        \n",
    "    patches = tf.squeeze(patches, axis=0)\n",
    "   \n",
    "    return tf.reshape(patches, [64, SQUARE_SIZE, SQUARE_SIZE, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = train_data['path'].values[0]\n",
    "image_file = tf.io.read_file(image_file)\n",
    "\n",
    "image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "\n",
    "# patches = process_image(image)\n",
    "# plt.imshow(patches)\n",
    "# plt.show()\n",
    "\n",
    "# print image shape of image patches\n",
    "# print(tf.shape(patches))\n",
    "\n",
    "# image_patches is 4 dimension array, you can use tf.squeeze to squeeze it, e.g.\n",
    "# image_patches = tf.squeeze(image_patches)\n",
    "\n",
    "# patch1 = patches[0,7,2,]\n",
    "\n",
    "# print(patch1)\n",
    "\n",
    "# reshape\n",
    "# patch1 = tf.reshape(patch1, [SQUARE_SIZE, SQUARE_SIZE, 3])\n",
    "# plt.imshow(patch1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_parse(filepath, preprocess_fn, img_dims):\n",
    "    image_file = tf.io.read_file(filepath)\n",
    "    image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "    image = preprocess_fn(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ds(df, batch_size, parse_fn, shuffle=False, augment_fn=None, num_parallel_calls=-1):\n",
    "    dataset_length = len(df)\n",
    "    \n",
    "    preprocess_fn = partial(tf.image.convert_image_dtype, dtype=tf.float32)\n",
    "    parse_fn = partial(parse_fn, preprocess_fn=preprocess_fn, img_dims=IMG_DIMS)\n",
    "    labels = [onehot_from_fen(fen) for fen in df.fen]\n",
    "    \n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(labels, tf.float32))\n",
    "    \n",
    "    dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices(df.path.values)\n",
    "        .map(parse_fn, num_parallel_calls=num_parallel_calls)\n",
    "        .map(augment_fn, num_parallel_calls=num_parallel_calls)\n",
    "    )\n",
    "    \n",
    "    ds = tf.data.Dataset.zip((dataset, label_ds))\n",
    "    \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(dataset_length)\n",
    "    \n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.prefetch(1)\n",
    "    return ds, dataset_length, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ZipDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "train_dataset, train_dataset_length, train_batch_size = prepare_ds(\n",
    "    train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    parse_fn=image_parse, \n",
    "    augment_fn=process_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ParallelMapDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "val_dataset, val_dataset_length, val_batch_size = prepare_ds(\n",
    "    train_data,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    parse_fn=image_parse,\n",
    "    augment_fn=process_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset(dataset, rows, cols):\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n",
    "    for i, (x, y) in enumerate(dataset.take(rows * cols)):\n",
    "        ax[i // cols, i % cols].axis('off')\n",
    "        ax[i // cols, i % cols].imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TakeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op IteratorGetNextSync in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (64, 40, 40, 3) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-0a66c0bca2bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-188-2656fbf6c279>\u001b[0m in \u001b[0;36mplot_dataset\u001b[0;34m(dataset, rows, cols)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5669\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5671\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5672\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 690\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (64, 40, 40, 3) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_dataset(train_dataset, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(\n",
    "    n_classes,\n",
    "    input_shape,\n",
    "    dropout=0.0,\n",
    "    l1=1e-8,\n",
    "    l2=1e-8,\n",
    "):\n",
    "    base_model = keras.applications.Xception(include_top=False, input_shape=input_shape)\n",
    "    x = keras.layers.concatenate([\n",
    "        keras.layers.GlobalAvgPool2D()(base_model.output),\n",
    "        keras.layers.GlobalMaxPool2D()(base_model.output),\n",
    "    ])\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Dropout(dropout)(x)\n",
    "    x = keras.layers.Dense(\n",
    "        n_classes,\n",
    "        kernel_regularizer=keras.regularizers.l1_l2(l1, l2),\n",
    "        activation=keras.activations.softmax,\n",
    "    )(x)\n",
    "    \n",
    "    return keras.Model(inputs=base_model.inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, lr, epochs, easing_epochs):\n",
    "    model.compile(\n",
    "        optimizer=optimizer(lr),\n",
    "        loss=keras.losses.sparse_categorical_crossentropy,\n",
    "        metrics=[\n",
    "            keras.metrics.sparse_categorical_accuracy,  \n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    reduce_lr_patience = max(5, epochs//4)\n",
    "    early_stopping_patience = reduce_lr_patience * 2\n",
    "    \n",
    "    history = model.fit(\n",
    "        x=train_dataset,\n",
    "        steps_per_epoch=math.ceil(train_dataset_length/train_batch_size),\n",
    "        validation_data=val_dataset,\n",
    "        validation_steps=math.ceil(val_dataset_length/val_batch_size),\n",
    "        epochs=epochs,\n",
    "        callbacks=[\n",
    "            keras.callbacks.ReduceLROnPlateau(factor=0.3, patience=reduce_lr_patience),\n",
    "            keras.callbacks.EarlyStopping(patience=early_stopping_patience, restore_best_weights=True),\n",
    "        ],\n",
    "        verbose=1,\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(\n",
    "    n_classes=13,\n",
    "    input_shape=IMG_DIMS + (3,),\n",
    "    dropout=0.2,\n",
    "    l1=3e-6,\n",
    "    l2=3e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 320, 320, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 159, 159, 32) 864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 159, 159, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 159, 159, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 157, 157, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 157, 157, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 157, 157, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 157, 157, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 157, 157, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 157, 157, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 157, 157, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 157, 157, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 79, 79, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 79, 79, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 79, 79, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 79, 79, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 79, 79, 128)  0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 79, 79, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 79, 79, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 79, 79, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 79, 79, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 79, 79, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 40, 40, 256)  32768       add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 40, 40, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 40, 40, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 40, 40, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 40, 40, 256)  0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 40, 40, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 40, 40, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 40, 40, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 40, 40, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 40, 40, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 20, 20, 728)  186368      add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 20, 20, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 20, 20, 728)  2912        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 20, 20, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 20, 20, 728)  0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 20, 20, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 20, 20, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 20, 20, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 20, 20, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 20, 20, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 20, 20, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 20, 20, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 20, 20, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 20, 20, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 20, 20, 728)  0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 20, 20, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 20, 20, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 20, 20, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 20, 20, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 20, 20, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 20, 20, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 20, 20, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 20, 20, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 20, 20, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 20, 20, 728)  0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 20, 20, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 20, 20, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 20, 20, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 20, 20, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 20, 20, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 20, 20, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 20, 20, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 20, 20, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 20, 20, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 20, 20, 728)  0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 20, 20, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 20, 20, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 20, 20, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 20, 20, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 20, 20, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 20, 20, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 20, 20, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 20, 20, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 20, 20, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 20, 20, 728)  0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 20, 20, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 20, 20, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 20, 20, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 20, 20, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 20, 20, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 20, 20, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 20, 20, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 20, 20, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 20, 20, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 20, 20, 728)  0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 20, 20, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 20, 20, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 20, 20, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 20, 20, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 20, 20, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 20, 20, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 20, 20, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 20, 20, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 20, 20, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 20, 20, 728)  0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 20, 20, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 20, 20, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 20, 20, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 20, 20, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 20, 20, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 20, 20, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 20, 20, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 20, 20, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 20, 20, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 20, 20, 728)  0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 20, 20, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 20, 20, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 20, 20, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 20, 20, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 20, 20, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 20, 20, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 20, 20, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 20, 20, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 20, 20, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 20, 20, 728)  0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 20, 20, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 20, 20, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 20, 20, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 20, 20, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 20, 20, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 10, 10, 1024) 745472      add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 10, 10, 1024) 4096        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_3 (GlobalM (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 4096)         0           global_average_pooling2d_3[0][0] \n",
      "                                                                 global_max_pooling2d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4096)         16384       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4096)         0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 13)           53261       dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,931,125\n",
      "Trainable params: 20,868,405\n",
      "Non-trainable params: 62,720\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_4 to have 4 dimensions, but got array with shape (16, 64, 40, 40, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-e5bae255a138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0measing_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-191-ab6c938cb47b>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, lr, epochs, easing_epochs)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_patience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         ],\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    894\u001b[0m     x, y, sample_weights = self._standardize_user_data(\n\u001b[1;32m    895\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m         extract_tensors_from_dataset=True)\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;31m# If `self._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2426\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2428\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    510\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_4 to have 4 dimensions, but got array with shape (16, 64, 40, 40, 3)"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    lr=1e-4,\n",
    "    epochs=5,\n",
    "    easing_epochs=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
